{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Testing different cascades"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "First let's count how many ears (positives) there are in our train set."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def count_ears_test():\n",
    "    nr_ears = 0\n",
    "    for photo in os.listdir('AWEForSegmentation/test'):\n",
    "        mask = cv2.imread(f'./AWEForSegmentation/testannot_rect/{photo}', 0).astype(bool)\n",
    "        i = 0\n",
    "        while i < mask.shape[0]:\n",
    "            j = 0\n",
    "            while j < mask.shape[1]:\n",
    "                if mask[i, j]:\n",
    "                    if i == 0 or not mask[i-1, j]:                  # upper row\n",
    "                        if j == 0 or not mask[i, j-1]:              # upper left corner\n",
    "                            nr_ears += 1\n",
    "                j += 1\n",
    "            i += 1\n",
    "    return nr_ears\n",
    "\n",
    "NR_EARS = count_ears_test()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Below we have functions for 2 tests, one on captured video from webcam and one on test images in *AWEForSegmentation*\n",
    "dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "def camera_test(cascade_folder):\n",
    "    \"\"\"Shows recognized ears with cascade from 'cascade_folder' on video from webcam.\"\"\"\n",
    "    # Load the cascade\n",
    "    ear_cascade = cv2.CascadeClassifier(f'{cascade_folder}/cascade.xml')\n",
    "\n",
    "    # To capture video from webcam.\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        # Read the frame\n",
    "        _, img = cap.read()\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # Detect the faces\n",
    "        ears = ear_cascade.detectMultiScale(img, 1.1, 100)\n",
    "        for (x, y, w, h) in ears:\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "        # Draw the rectangle around each ear\n",
    "        # Display\n",
    "        cv2.imshow('img', img)\n",
    "        # Stop if escape key is pressed\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k==27:\n",
    "            break\n",
    "    # Release the VideoCapture object\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "def awe_test(cascade_folder, scaleFactor, minNeighbours, test_visual_folder=None):\n",
    "    \"\"\"Tests cascade from 'cascade_folder' using parameters 'scaleFactor' and 'minNeighbours'.\n",
    "    If test_visual_folder is provided, the function will create a visual representation in folder 'test'.\"\"\"\n",
    "    results = {'avgIoU': 0, 'TP': 0, 'FP': 0}     # results will be averaged over all test images\n",
    "    ear_cascade = cv2.CascadeClassifier(f'{cascade_folder}/cascade.xml')\n",
    "    if test_visual_folder:\n",
    "        if not os.path.exists(f'test/{test_visual_folder}'):\n",
    "                os.makedirs(f'test/{test_visual_folder}')\n",
    "    n = 0\n",
    "    for photo in os.listdir('AWEForSegmentation/test'):\n",
    "        mask = cv2.imread(f'./AWEForSegmentation/testannot_rect/{photo}', 0) / 255\n",
    "        img = cv2.imread(f'./AWEForSegmentation/test/{photo}', cv2.IMREAD_UNCHANGED)\n",
    "        ears = ear_cascade.detectMultiScale(img, scaleFactor, minNeighbours)\n",
    "        avg_iou = 0\n",
    "        for (x, y, w, h) in ears:\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), (0, 0, 255), 2)  # Draw the rectangle around each ear\n",
    "            intersection = mask[y:y+h, x:x+h]\n",
    "            union = mask.copy()\n",
    "            union[y:y+h, x:x+h] = 1\n",
    "            iou = np.sum(intersection) / np.sum(union)\n",
    "            avg_iou += iou\n",
    "            n += 1\n",
    "            if iou > 0.5:\n",
    "                results['TP'] += 1\n",
    "            else:\n",
    "                results['FP'] += 1\n",
    "        if len(ears):\n",
    "            results['avgIoU'] += avg_iou\n",
    "        if test_visual_folder:\n",
    "            cv2.imwrite(f'test/{test_visual_folder}/{photo[:4]}_{cascade_folder}.png', img)\n",
    "    results['avgIoU'] /= n\n",
    "    results['TPR'] = results['TP'] / NR_EARS            # recall / true positive rate\n",
    "    results['PPV'] = results['TP'] / (results['TP'] + results['FP'])    # precision / positive predictive value\n",
    "    results['F1'] = 2 * results['TPR'] * results['PPV'] / (results['TPR'] + results['PPV'])     # F1 score\n",
    "    return results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "camera_test('cascadecoco_people')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next block creates a table *results* that holds test results for different cascades and minNeighbours parameter used in\n",
    "detection."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "cascades = ['cascade_basic', 'cascade_basic_all', 'cascade_basic_maxFAR03', 'cascade_basic_all_maxFAR03', 'cascade_gs',\n",
    "            'cascade_gs_all', 'cascade_gs_maxFAR', 'cascade_gs_maxFAR03','cascade_coco', 'cascade_coco_people', 'cascade_combined']\n",
    "min_neigh = [5, 25, 50, 100, 150]\n",
    "results = pd.DataFrame(columns=cascades)\n",
    "for cascade_folder in cascades:\n",
    "    cascade_dict = {}\n",
    "    for mn in min_neigh:\n",
    "        res = awe_test(cascade_folder, 1.1, mn)\n",
    "        for key in res:\n",
    "            cascade_dict[(key, mn)] = res[key]\n",
    "    results[cascade_folder] = pd.Series(cascade_dict).sort_index()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}