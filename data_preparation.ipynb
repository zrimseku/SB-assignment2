{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Data preparation for ear cascade training\n",
    "Positive images are already in *AWEForSegmentation* dataset, we only need to make the description file with positions\n",
    "of the masks. That is implemented in function `positive_description_file`.\n",
    "The mask for photo `0417.png` was bigger than the photo, so I fixed that with the last function in the block below.\n",
    "\n",
    "We still need to find negative images, that are images that don't include any ears.\n",
    "For starters I got them with function `prepare_negative_from_positive`, that takes positive images and builds twice as\n",
    "many negatives, by putting black and white squares over ears in the positive images. This function also writes the\n",
    "negative description file for these images."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def positive_description_file():\n",
    "    info = {}\n",
    "    for photo in os.listdir('AWEForSegmentation/train'):\n",
    "        mask = cv2.imread(f'./AWEForSegmentation/trainannot_rect/{photo}', 0).astype(bool)\n",
    "        info[photo] = []\n",
    "        unfinished = {}\n",
    "        i = 0\n",
    "        while i < mask.shape[0]:\n",
    "            j = 0\n",
    "            while j < mask.shape[1]:\n",
    "                if mask[i, j]:\n",
    "                    if i == 0 or not mask[i-1, j]:                  # upper row\n",
    "                        if j == 0 or not mask[i, j-1]:              # upper left corner\n",
    "                            unfinished[j] = {'start_y': i}          # there can only be one unfinished on y=j\n",
    "                            width = 0\n",
    "                            while j < mask.shape[1] and mask[i, j]:\n",
    "                                j += 1\n",
    "                                width += 1\n",
    "                            unfinished[j-width]['width'] = width\n",
    "                    elif mask[i-1, j] and mask[i+1, j]:             # left column\n",
    "                        j += unfinished[j]['width']\n",
    "                    elif mask[i-1, j] and not mask[i+1, j]:         # lower left corner\n",
    "                        height = i - unfinished[j]['start_y'] + 1\n",
    "                        info[photo].append([j, unfinished[j]['start_y'], unfinished[j]['width'], height])\n",
    "                        j += unfinished[j]['width']\n",
    "                    else:\n",
    "                        print(photo, i, j)\n",
    "                else:\n",
    "                    j += 1\n",
    "            i += 1\n",
    "    with open('info.dat', 'w') as f:\n",
    "        for photo in info:\n",
    "            entry = f\"AWEForSegmentation/train/{photo}  {len(info[photo])}  \"\n",
    "            for el in info[photo]:\n",
    "                entry += ' '.join(map(str, el)) + \"   \"\n",
    "            f.write(entry.strip() + \"\\n\")\n",
    "    return info\n",
    "\n",
    "def prepare_negative_from_positive():\n",
    "    info = []\n",
    "    for photo in os.listdir('AWEForSegmentation/train'):\n",
    "        mask = cv2.imread(f'./AWEForSegmentation/trainannot_rect/{photo}', 0).astype(bool)\n",
    "        negative = cv2.imread(f'./AWEForSegmentation/train/{photo}', cv2.IMREAD_COLOR)\n",
    "        negative[mask] = (0, 0, 0)\n",
    "        cv2.imwrite(f'AWEForSegmentation/negative/n_{photo}', negative)\n",
    "        info.append(f'AWEForSegmentation/negative/n_{photo}')\n",
    "        negative[mask] = (255, 255, 255)\n",
    "        cv2.imwrite(f'AWEForSegmentation/negative/n_1{photo[1:]}', negative)\n",
    "        info.append(f'AWEForSegmentation/negative/n_1{photo[1:]}')\n",
    "    with open('negative_start.txt', 'w') as f:\n",
    "        for line in info:\n",
    "            f.write(line + \"\\n\")\n",
    "\n",
    "def repair_mask_0417():\n",
    "    \"\"\"Mask of photo 0417.png is of size (360, 481) and photo is (360, 480)\"\"\"\n",
    "    mask = cv2.imread(f'./AWEForSegmentation/trainannot_rect/0417.png', -1)\n",
    "    new_mask = mask[:, :480]\n",
    "    cv2.imwrite(f'AWEForSegmentation/trainannot_rect/0417.png', new_mask)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "repair_mask_0417()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "positive_description_file()\n",
    "prepare_negative_from_positive()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Different selections of negative images\n",
    "\n",
    "#### Grayscale images\n",
    "I downloaded a set of grayscale images from [Kaggle](https://www.kaggle.com/muhammadkhalid/negative-images) and saved\n",
    "them to folder *neg_img_gs*."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def negative_description_file(path, file_name):\n",
    "    \"\"\"Make description file named 'file_name' for negative images in 'path'.\"\"\"\n",
    "    with open(file_name, 'w') as f:\n",
    "        for photo in os.listdir(path):\n",
    "            f.write(f'{path}/{photo}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "negative_description_file('neg_img_gs', 'negative_gs.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Images from COCO\n",
    "To find better negative images I used *COCO* dataset, to be able to select images with certain objects.\n",
    "I downloaded  *2017 Train/Val annotations* from [COCO website](https://cocodataset.org/#download) and saved them to\n",
    "folder *COCO/annotations*. From the annotations we only need *instances_train2017.json*, but it is too big to be\n",
    "included on git, so you need to download it separately for this code to be reproducible.\n",
    "\n",
    "Conda installation doesn't work on Windows, so I used `pip install pycocotools-windows` to get the tools needed to\n",
    "download those images that contain the right objects."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=29.09s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "coco = COCO('COCO/annotations/instances_train2017.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO categories: \n",
      "person .  bicycle .  car .  motorcycle .  airplane .  bus .  train .  truck .  boat .  traffic light .  fire hydrant .  stop sign .  parking meter .  bench .  bird .  cat .  dog .  horse .  sheep .  cow .  elephant .  bear .  zebra .  giraffe .  backpack .  umbrella .  handbag .  tie .  suitcase .  frisbee .  skis .  snowboard .  sports ball .  kite .  baseball bat .  baseball glove .  skateboard .  surfboard .  tennis racket .  bottle .  wine glass .  cup .  fork .  knife .  spoon .  bowl .  banana .  apple .  sandwich .  orange .  broccoli .  carrot .  hot dog .  pizza .  donut .  cake .  chair .  couch .  potted plant .  bed .  dining table .  toilet .  tv .  laptop .  mouse .  remote .  keyboard .  cell phone .  microwave .  oven .  toaster .  sink .  refrigerator .  book .  clock .  vase .  scissors .  teddy bear .  hair drier .  toothbrush\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display COCO categories\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "names = [cat['name'] for cat in categories]\n",
    "print('COCO categories: \\n{}\\n'.format(' .  '.join(names)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "ids = {}\n",
    "# get all images containing given categories\n",
    "ids[\"livingroom\"] = coco.getImgIds(catIds=coco.getCatIds(catNms=['couch', 'chair', 'tv']))\n",
    "ids[\"kitchen\"] = coco.getImgIds(catIds=coco.getCatIds(catNms=['dining table', 'refrigerator', 'oven']))\n",
    "ids[\"bedroom\"] = coco.getImgIds(catIds=coco.getCatIds(catNms=['bed', 'book']))\n",
    "ids[\"park\"] = coco.getImgIds(catIds=coco.getCatIds(catNms=['bicycle', 'bench']))\n",
    "ids[\"traffic\"] = coco.getImgIds(catIds=coco.getCatIds(catNms=['bus', 'car', 'traffic light']))\n",
    "ids[\"outside\"] = coco.getImgIds(catIds=coco.getCatIds(catNms=['dog', 'backpack']))\n",
    "ids[\"lunch\"] = coco.getImgIds(catIds=coco.getCatIds(catNms=['table', 'cup', 'bowl', 'bottle']))\n",
    "ids[\"office\"] = coco.getImgIds(catIds=coco.getCatIds(catNms=['mouse', 'keyboard', 'laptop']))\n",
    "\n",
    "people = coco.getImgIds(catIds=coco.getCatIds(catNms=['person']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# separate photos that don't contain people, and those containing people that need to be manually checked for ears.\n",
    "ids_no_people = []\n",
    "ids_people = []\n",
    "for key in ids:\n",
    "    ids_no_people.extend([i for i in ids[key] if i not in people])\n",
    "    ids_people.extend([i for i in ids[key] if i in people])\n",
    "\n",
    "combined = list(dict.fromkeys(ids_no_people))\n",
    "combined_with_people = list(dict.fromkeys(ids_people))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# download images\n",
    "coco.download('no_people', combined)\n",
    "coco.download('including_people', combined_with_people)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cascade trained on photos without people (cascade in folder *cascadecoco*) still wasn't better from previous cascades,\n",
    "it was still recognising many false positives. False positives were mainly on people, so I also downloaded photos that\n",
    "include people, and then manually deleted those that include visible ears. In folder *coco_incl_people* I have\n",
    "photos from folder *no_people* combined with photos from folder *including_people* that don't include ears\n",
    "(cascade in *cascadecoco_people*).\n",
    "\n",
    "For reproducing the code you don't need to manually delete images, but you should take the negative file directly from\n",
    "my git repository - it includes a list of images that should be in the folder, so cascade will ignore the others."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "negative_description_file('no_people', 'negative_coco.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# only run this, if you manually delete images that include ears - otherwise take 'negative_coco_people.txt' from git.\n",
    "# negative_description_file('coco_incl_people', 'negative_coco_people.txt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For final set of images I decided to combine all off the images gathered above, put them in folder *all_images*, and\n",
    "create cascade in folder *cascade_combined*. To avoid having too many unneeded photos I took only photos with black\n",
    "squares from *AWEForSegmentation/negative*."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "negative_description_file('all_images', 'negative_all.txt')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-assignment-2-py",
   "language": "python",
   "display_name": "Python [conda env:assignment-2] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}